## Monday, June 21, 2021   11:00 – 13:30

* Transformer Interpretability Beyond Attention Visualization

* Single-Stage Instance Shadow Detection with Bidirectional Relation Learning

* AQD: Towards Accurate Quantized Object Detection, latency VS object detection

* UP-DETR: Unsupervised Pre-training for Object Detection with Transformers

* The Lottery Ticket Hypothesis for Object Recognition

* Dual Contradistinctive Generative Autoencoder

* Cross-Modal Contrastive Learning for Text-to-Image Generation

* Spatially Consistent Representation Learning

## Monday, June 21, 2021   22:00  – 24:30

* SAIL-VOS 3D: A Synthetic Dataset and Baselines for Object Detection and 3D Mesh Reconstruction From Video Data

* Closed-Form Factorization of Latent Semantics in GANs

* Transformer Meets Tracker: Exploiting Temporal Context for Robust Visual Tracking

* UP-DETR: Unsupervised Pre-Training for Object Detection With Transformers

* One Thing One Click: A Self-Training Approach for Weakly Supervised 3D Semantic Segmentation

* Towards Long-Form Video Understanding

* Pose Recognition with Cascade Transformers

* 3D-MAN: 3D Multi-frame Attention Network for Object Detection

* Distilling Object Detectors via Decoupled Features

* Re-Labeling ImageNet: From Single to Multi-Labels, From Global to Localized Labels

* Unsupervised Visual Representation Learning by Tracking Patches in Video

* BBAM: Bounding Box Attribution Map for Weakly Supervised
Semantic and Instance Segmentation
